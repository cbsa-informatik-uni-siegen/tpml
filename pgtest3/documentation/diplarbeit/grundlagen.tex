%%
%% Grundlagen
%%


\chapter{Grundlagen}
\label{chapter:Grundlagen}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Mathematisch Grundlagen %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Mathematische Grundlagen}

Im folgenden geben wir eine kurze Einf\"uhrung in die in diesem Dokument verwendete Mathematik,
welche im wesentlichen auf den Ausf\"uhrungen in \cite{Doerfler88} basiert. F\"ur den Leser
soll dieser Abschnitt lediglich als R\"uckblick oder Ged\"achtnisst\"utze dienen.

{\bf TODO:} Potenzmenge definieren.

\begin{definition}[Eigenschaften von Relationen]
  Sei $M$ eine beliebige Menge und $R \subseteq M \times M$ eine bin\"are Relation in $M$.
  \begin{enumerate}
    \item $R$ heisst {\em reflexiv}, wenn $(x,x)\in{R}$ f\"ur alle $x\in{M}$ gilt.
    \item $R$ heisst {\em transitiv}, wenn f\"ur alle $x,y,z\in{M}$ aus $(x,y)\in{R}$ und
          $(y,z)\in{R}$ folgt, dass auch $(x,z)\in{R}$ gilt.
    \item $R$ heisst {\em symmetrisch}, wenn f\"ur alle $x,y\in{M}$ aus $(x,y)\in{R}$ folgt,
          dass auch $(y,x)\in{R}$ gilt.
    \item $R$ heisst {\em antisymmetrisch}, wenn f\"ur alle $x,y\in{M}$ aus $(x,y)\in{R}$
          und $(y,x)\in{R}$ folgt, dass $y = x$ gilt.
  \end{enumerate}
\end{definition}

\begin{definition}[Ordnungsrelationen]
  Sei $D$ eine beliebige Menge und $\sqsubseteq\ \subseteq D \times D$ eine bin\"are Relation in $D$.
  \begin{enumerate}
    \item $(D,\sqsubseteq)$ heisst {\em Quasiordnung}, wenn $\sqsubseteq$ reflexiv und transitiv ist.
    \item Eine Quasiordnung $(D,\sqsubseteq)$ heisst {\em partielle Ordnung} (engl.: {\em partial order}, kurz
          {\em po}), wenn $\sqsubseteq$ zus\"atzlich antisymmetrisch ist.
    \item Eine partielle Ordnung $(D,\sqsubseteq)$ heisst {\em total}, wenn $x \sqsubseteq y$ oder
          $y \sqsubseteq x$ f\"ur alle $x,y\in{D}$ gilt.
    \item Eine Quasiordnung $(D,\sqsubseteq)$ heisst {\em \"Aquivalenzrelation}, wenn $\sqsubseteq$ zus\"atzlich
          symmetrisch ist.
  \end{enumerate}
\end{definition}

Wenn aus dem Kontext ersichtlich ist, auf welche Menge Bezug genommen wird, l\"asst man auch die Menge
weg und schreibt nur die Relation, also $\sqsubseteq$ statt $(D,\sqsubseteq)$. Entsprechend schreibt
man auch lediglich $D$, wenn klar ist, wie die Menge geordnet wird.


\begin{definition}
{\bf TODO:} Schreibweise f\"ur Abbildungen in diesem Dokument.
  Seien $A$, $B$ Mengen, $a \in A$, $b \in B$ und $f: A \pto B$ eine partielle Funktion. Dann
  bezeichnet $f\SUB{b}{a}$ die partielle Funktion $g: A \pto B$ mit den folgenden Eigenschaften.
  \begin{itemize}
    \item $\dom{g} = \dom{f}\,\cup\,\{a\}$
    \item $g(a) = b$
    \item $\forall a'\in\dom{g}:\,a' \ne a\,\Rightarrow\,g(a') = f(a')$
  \end{itemize}
\end{definition}


%%%%%%%%%%%%%%%%%%%%%
%% Bereichstheorie %%
%%%%%%%%%%%%%%%%%%%%%

\subsection{Bereichstheorie}
\label{abschnitt:Bereichstheorie}

Dieser Abschnitt bietet eine kurze Einf\"uhrung in die wichtigstens Begriffe der Bereichstheorie, und stellt
insbesondere den Fixpunktsatz von Kleene vor. Die folgenden Ausf\"uhrungen basieren im wesentlichen auf dem
Material der Vorlesungen "`Theorie der Programmierung III"' \cite{Sieber07} und "`Semantik von Programmiersprachen"'
\cite[S.85ff]{Kindler05}.

\begin{definition} \label{definition:math:Schranken}
  Sei $(D,\sqsubseteq)$ eine partielle Ordnung und $S \subseteq D$.
  \begin{enumerate}
    \item $d\in{S}$ heisst {\em kleinstes Element} von $S$, wenn $d\sqsubseteq{s}$ f\"ur alle $s\in{S}$.
    \item $d\in{D}$ heisst {\em obere Schranke} von $S$, wenn $s\sqsubseteq{d}$ f\"ur alle $s\in{S}$.
    \item $d\in{S}$ heisst {\em kleinste obere Schranke} oder {\em Supremum} von $S$, wenn $d$ kleinstes
          Element der Menge aller oberen Schranken von $S$ ist.
  \end{enumerate}
\end{definition}
%
Analog zur oberen Schranke definiert man den Begriff der {\em unteren Schranke} und das
{\em Infimum} als gr\"osstes Element der Menge aller unteren Schranken. Wenn $D$ selbst ein kleinstes
Element besitzt, so bezeichnet man dieses Element mit $\bot$ oder $\bot_D$. Entsprechend bezeichnet
man ein gr\"osstes Element mit $\top$ oder $\top_D$. Das Supremum einer Menge $S \subseteq D$ bezeichnet
man mit $\bigsqcup S$ oder $\bigsqcup_D S$, das Infimum mit $\bigsqcap S$ oder $\bigsqcap_D S$.

\begin{definition}[Gerichtete Ordnungen] \label{definition:math:dcpo}
  Sei $(D,\sqsubseteq)$ eine partielle Ordnung.
  \begin{enumerate}
    \item Eine Menge $\Delta \subseteq D$ heisst {\em gerichtet} (engl.: {\em directed}), wenn
          $\Delta \ne \emptyset$ und zu je zwei Elementen $d_1,d_2\in\Delta$ existiert ein
          $d\in\Delta$ mit $d_1\sqsubseteq{d}$ und $d_2\sqsubseteq{d}$.

    \item $(D,\sqsubseteq)$ heisst {\em gerichtet vollst\"andig} (engl.: {\em directed complete
          partial order}, kurz {\em dcpo}), wenn jede gerichtete Teilmenge von $D$ ein
          Supremum besitzt.
  \end{enumerate}
\end{definition}

\begin{lemma} \label{lemma:math:Potenzmengen_sind_dcpos}
  Sei $M$ eine beliebige Menge. Dann gilt:
  \begin{enumerate}
    \item $\bigl(\mathcal{P}(M),\subseteq\bigr)$ ist eine dcpo mit kleinstem Element $\emptyset$.
    \item $\bigl(\mathcal{P}(M),\supseteq\bigr)$ ist eine dcpo mit kleinstem Element $M$.
  \end{enumerate}
\end{lemma}

\begin{beweis} \
  \begin{enumerate}
    \item Es ist ziemlich offensichtlich, dass $\emptyset$ bez\"uglich $\subseteq$ das kleinste
          Element jeder Potenzmenge ist, ebenso wie es trivialerweise ersichtlich ist, dass jede
          Potenzmenge durch $\subseteq$ partiell geordnet wird. Damit bleibt zu zeigen, dass jede
          gerichtete Teilmenge von $\mathcal{P}(M)$ ein Supremum besitzt.

          Sei also $\Delta\subseteq\mathcal{P}(M)$ gerichtet. Dann ist $\bigcup \Delta$ eine
          obere Schranke von $\Delta$, denn es gilt $\delta \subseteq \bigcup \Delta$ f\"ur
          alle $\delta \in \Delta$. Es ist ziemlich offensichtlich, dass keine kleinere
          obere Schranke von $\Delta$ existiert, also ist $\bigcup \Delta$ das Supremum
          von $\Delta$.

    \item Folgt analog zur ersten Aussage des Lemmas.
  \end{enumerate}
\end{beweis}

\begin{definition}[Monotone und stetige Abbildungen] \label{definition:math:Monotonie_und_Stetigkeit}
  Seien $(D,\sqsubseteq_D)$ und $(E,\sqsubseteq_E)$ dcpos.
  \begin{enumerate}
    \item Eine (totale) Abbildung $f: D \to E$ heisst {\em monoton}, wenn f\"ur alle $d_1,d_2\in{D}$ gilt:
          \[\begin{array}{rcl}
            d_1 \sqsubseteq_D d_2 & \Rightarrow & f(d_1) \sqsubseteq_E f(d_2)
          \end{array}\]
    \item Eine monotone Abbildung $f: D \to E$ heisst {\em stetig}, wenn f\"ur jede gerichtete Teilmenge
          $\Delta\subseteq{D}$ gilt:
          \[\begin{array}{rcl}
            f(\bigsqcup_D \Delta) & = & \bigsqcup_E f(\Delta)
          \end{array}\]
  \end{enumerate}
\end{definition}

\begin{korollar}
  Seien $D,E$ dcpos und sei $f: D \to E$ eine monotone Abbildung. $f$ ist genau dann {\em stetig}, wenn
  f\"ur jede gerichtete Teilmenge $\Delta\subseteq{D}$ gilt:
  \[\begin{array}{rcl}
    f(\bigsqcup_D \Delta) & \sqsubseteq_E & \bigsqcup_E f(\Delta)
  \end{array}\]
\end{korollar}

\begin{beweis}
  Klar, da die G\"ultigkeit von $\sqsupseteq_E$ bereits aus der Monotonie von $f$ folgt, denn es gilt:
  $\bigsqcup_D \Delta$ ist eine obere Schranke von $\Delta$, also ist $f(\bigsqcup_D \Delta)$ eine obere
  Schranke von $f(\Delta)$, und damit $f(\bigsqcup_D \Delta)\ \sqsupseteq_E\ \bigsqcup_E f(\Delta)$.
\end{beweis}

Mit diesen Begriffen l\"a"st sich nun der Fixpunktsatz von Kleene formulieren und beweisen. Im Gegensatz zum
wohlbekannten Fixpunktsatz von Knaster und Tarski, dem sogenannten {\em Knaster-Tarski-Theorem} \cite{Tarski55},
stellt man hier eine strengere Forderung an die Funktion, n\"amlich Stetigkeit statt nur Monotonie, erh\"alt
daf\"ur aber ein konstruktives Verfahren zur Bildung des kleinsten Fixpunktes.

\begin{satz}[Fixpunktsatz von Kleene] \label{satz:math:Fixpunktsatz_von_Kleene}
  Sei $D$ eine dcpo, die ein kleinstes Element $\bot$ besitzt, und $f: D \to D$ eine stetige Abbildung.
  Dann gilt:
  \begin{enumerate}
    \item Die Menge $\{f^n(\bot)\,|\,n\in\setN\}$ ist gerichtet.
    \item $\mu f = \bigsqcup \{f^n(\bot)\,|\,n\in\setN\}$ ist kleinster Fixpunkt von $f$.
  \end{enumerate}
\end{satz}
%
Statt $\bigsqcup \{f^n(\bot)\,|\,n\in\setN\}$ verwendet man h\"aufig die Kurzschreibweise
$\bigsqcup_{n\in\setN} f^n(\bot)$.

\begin{beweis} \
  \begin{enumerate}
    \item Es gilt $\bot \sqsubseteq f(\bot)$, da $\bot$ nach Voraussetzung kleinstes Element von $D$ ist.
          Wegen der Monotonie von $f$ folgt daraus $f(\bot) \sqsubseteq f^2(\bot)$, was sich durch
          vollst\"andige Induktion auf $f^n(\bot) \sqsubseteq f^{n+1}(\bot)$ f\"ur alle $n\in\setN$
          erweitern l\"asst. Wegen der Transitivit\"at von $\sqsubseteq$ folgt damit, dass
          $\{f^n(\bot)\,|\,n\in\setN\}$ gerichtet ist.
    
    \item Wir zeigen zun\"achst, dass $\mu f$ ein Fixpunkt von $f$ ist, also:
          \[\begin{array}{rcl}
            f(\mu f) & = & f(\bigsqcup_{n\in\setN} f^n(\bot)) \\
                     & = & \bigsqcup_{n\in\setN} f^{n+1}(\bot) \\
                     & = & \bigsqcup_{n\in\setN} f^n(\bot) \\
                     & = & \mu f
          \end{array}\]

          Es bleibt noch zu zeigen, dass $\mu f$ der kleinste Fixpunkt ist. Sei dazu $d \in D$ ein
          beliebiger Fixpunkt von $f$, also $f(d) = d$. Da $\mu f = \bigsqcup_{n\in\setN} f^n(\bot)$
          die kleinste obere Schranke aller $f^n(\bot)$ ist, gen\"ugt es zu zeigen, dass $d$ eine
          obere Schranke von $\{f^n(\bot)\,|\,n\in\setN\}$ ist. Dazu zeigen wir durch vollst\"andige
          Induktion \"uber $n$, dass $f^n(\bot) \sqsubseteq d$ f\"ur alle $n\in\setN$:
          \begin{itemize}
            \item $n=0$

                  $f^0(\bot) = \bot \sqsubseteq d$

            \item $n\leadsto{n+1}$

                  Nach Induktionsvoraussetzung gilt $f^n(\bot) \sqsubseteq d$. Daraus folgt
                  \[\begin{array}{rclclcl}
                    f^{n+1}(\bot) & = & f(f^n(\bot)) & \sqsubseteq & f(d) & = & d,
                  \end{array}\]
                  da $f$ monoton ist und $d$ nach Annahme ein Fixpunkt von $f$ ist.
          \end{itemize}
  \end{enumerate}
\end{beweis}

{\bf TODO:} Vielleicht noch Prosa?


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Induktion und Coinduktion %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsection{Induktion und Coinduktion}
%\label{subsection:math:Induktion_und_Coinduktion}
%
%In diesem Abschnitt stellen wir kurz das Prinzip der Induktion und das Prinzip der Coinduktion vor. Dabei
%geben wir nur eine kurze Einleitung basierend auf \cite{Jacobs97} und \cite{Pierce02} ({\bf TODO:} Mehr
%Quellen, weitergehende Literatur, siehe Pierce, Seite 312 f\"ur Quellen). Sei dazu $\setU$ eine universelle
%Menge, also irgendein Universum von Elementen, f\"ur die etwas gezeigt werden soll.
%
%\begin{definition} \label{definition:math:Monotone_Funktionen}
%  Eine Funktion $F: \mathcal{P}(\setU \times \setU) \to \mathcal{P}(\setU \times \setU)$ heisst
%  {\em monoton}, wenn f\"ur alle $X,Y\subseteq \setU \times \setU$ gilt:
%  $X \subseteq Y\,\Rightarrow\,F(X) \subseteq F(Y)$
%\end{definition}
%
%Im Folgenden nehmen wir an, dass $F$ eine monotone Funktion auf $\mathcal{P}(\setU\times\setU)$ ist.
%Eine solche Funktion $F$ wird auch als {\em generierende Funktion} (engl.: {\em generating function})
%bezeichnet.
%
%\begin{definition} \label{definition:math:Fixpunkt}
%  Sei $X \subseteq \setU\times\setU$.
%  \begin{enumerate}
%    \item $X$ heisst {\em $F$-abgeschlossen} (engl.: {\em $F$-closed}), wenn $F(X)\subseteq X$.
%    \item $X$ heisst {\em $F$-konsistent} (engl.: {\em $F$-consistent}), wenn $X \subseteq F(X)$.
%    \item $X$ heisst {\em Fixpunkt} von $F$, wenn $F(X) = X$. \index{Fixpunkt}
%  \end{enumerate}
%\end{definition}
%
%Stellt man sich die Elemente von $\setU \times \setU$ als Aussagen \"uber Elemente des Universums vor, und $F$
%als eine Relation, die angibt, welche zus\"atzlichen Aussagen aus einer gegebenen Aussagenmenge folgen,
%so kann eine $F$-abgeschlossene Menge nicht verg\"ossert werden, durch Aussagen, die mittels $F$
%aus ihr folgen. Sie enth\"alt bereits alle Aussagen, die aus $X$ folgen. Entsprechend enth\"alt eine
%$F$-konsistente Menge bereits s\"amtliche Pr\"amissen f\"ur die in ihr enthaltenen Aussagen.
%Ein Fixpunkt ist also eine Menge von Aussagen, die sowohl alle Pr\"amissen, wie auch alle notwendigen
%Pr\"amissen beinhaltet.
%
%Die Anwendung des Knaster-Tarski-Theorem (vgl. \cite{Tarski55}) sichert uns die Existenz von zumindest
%einem Fixpunkt einer generierenden Funktion $F$ und liefert dar\"uber hinaus ein Verfahren zur
%Bestimmung des kleinsten und des gr\"o"sten Fixpunkts einer generierenden Funktion $F$.
%
%\begin{satz}[Knaster-Tarski] \label{satz:math:Knaster_Tarski} \
%  \begin{enumerate}
%    \item Der Durchschnitt aller $F$-abgeschlossenen Mengen ist der kleinste Fixpunkt von $F$.
%    \item Die Vereinigung aller $F$-konsistenten Mengen ist der gr\"o"ste Fixpunkt von $F$.
%  \end{enumerate}
%\end{satz}
%
%\begin{beweis} \
%  \begin{enumerate}
%    \item Sei $A = \{X\ |\ F(X) \subseteq X\}$ die Klasse aller $F$-abgeschlossenen Mengen, und sei weiter
%          $P = \bigcap_{X \in A} X$ der Durchschnitt all dieser Mengen. Wegen der Monotonie und wegen
%          $P \subseteq X$ f\"ur alle $X \in A$ gilt $F(P) \subseteq F(X)$. Da $X$ $F$-abgeschlossen ist,
%          folgt $F(X) \subseteq X$, und somit $F(P) \subseteq F(X) \subseteq X$. Wenn $F(P)$ Teilmenge
%          jeder solchen Menge $X$ ist, dann ist $F(P)$ auch Teilmenge des Durchschnitts aller $X$,
%          also $F(P) \subseteq \bigcap_{X \in A} X = P$. Das heisst $P$ ist wieder eine $F$-abgeschlossene
%          Menge. Dar\"uberhinaus folgt $F(F(P)) \subseteq F(P)$, da $F$ eine monotone Funktion ist. Also
%          ist $F(P) \in A$ nach Definition von $A$, und es gilt $P \subseteq F(P)$. Insgesamt ist damit
%          gezeigt, dass $P$ ein Fixpunkt der Funktion $F$ ist, und dass $P$ die kleinste $F$-abgeschlossene
%          Menge ist, also muss $P$ der kleinste Fixpunkt von $F$ sein.
%
%    \item Sei $K = \{X\ |\ X \subseteq F(X)\}$ die Klasse aller $F$-konsistenten Mengen, und sei weiter
%          $P = \bigcup_{X \in K} X$ die Vereinigung all dieser Mengen. Da $F$ nach Voraussetzung eine
%          monotone Funktion ist und f\"ur alle $X \in K$ gilt $X \subseteq P$, erhalten wir
%          $F(X) \subseteq F(P)$. Da $K$ ausschliesslich $F$-konsistente Mengen enth\"alt gilt weiter
%          $X \subseteq F(X)$, also folgt $X \subseteq F(X) \subseteq F(P)$. Da dies f\"ur alle $X \in K$
%          gilt, folgt unmittelbar $P = \bigcup_{X \in K} X \subseteq F(P)$, also ist $P$ ebenfalls eine
%          $F$-konsistente Menge. Nach Definition ist $P$ damit die gr\"o"ste $F$-konsistente Menge.
%          Wegen der Monotonie von $F$ erhalten wir $F(P) \subseteq F(F(P))$. Nach Definition von $K$ gilt
%          $F(P) \in K$, also $F(P) \subseteq P$. Damit ist gezeigt, dass $P$ sowohl die gr\"o"ste
%          $F$-konsistente Menge ist, und dar\"uber hinaus ein Fixpunkt von $F$. Also muss $P$ der
%          gr\"o"ste Fixpunkt von $F$ sein.
%  \end{enumerate}
%\end{beweis}
%
%\begin{definition}
%  \index{Fixpunkt!kleinster}
%  \index{Fixpunkt!gr\"o"ster}
%  Den kleinsten Fixpunkt von $F$ bezeichnen wir mit $\mu F$. Den gr\"o"sten Fixpunkt von $F$ bezeichnen
%  wir mit $\nu F$.
%\end{definition}
%
%Damit l\"a"st sich nun das Prinzip der Induktion und das Prinzip der Coinduktion jeweils als Korollar
%von Satz~\ref{satz:math:Knaster_Tarski} wie folgt formulieren.
%
%\begin{korollar}[Prinzip der Induktion] \label{korollar:math:Prinzip_der_Induktion} \index{Induktion} \
%  Wenn $X$ $F$-abgeschlossen, dann $\mu F \subseteq X$.
%\end{korollar}
%
%\begin{korollar}[Prinzip der Coinduktion] \label{korollar:math:Prinzip_der_Coinduktion} \index{Coinduktion} \
%  Wenn $X$ $F$-konsistent, dann $X \subseteq \nu F$.
%\end{korollar}
%%
%Beide Korollar folgen unmittelbar aus dem Knaster-Tarski-Theorem (Satz~\ref{satz:math:Knaster_Tarski}). Wir
%setzen voraus, dass dem Leser das Induktionsprinzip bekannt ist, und beschr\"anken uns deshalb im Folgenden
%darauf, einige im sp\"ateren Verlauf des Dokuments ben\"otigte Eigenschaften von Relationen mit Coinduktion
%zu beweisen. Die n\"achsten Definitionen sollte keine grosse \"Uberraschung f\"ur den Leser darstellen.
%
%\begin{definition}[Reflexivit\"at] \label{definition:math:Reflexivitaet}
%  Eine Relation $R \subseteq \setU\times\setU$ heisst {\em reflexiv}, wenn $R$ die Relation
%  \[\begin{array}{l}
%    \name{Refl}_{\setU} := \{(x,x)\ |\ x\in\setU\}
%  \end{array}\]
%  enth\"alt, also $\name{Refl}_{\setU} \subseteq R$.
%\end{definition}
%
%\begin{definition}[Transitivit\"at] \label{definition:math:Transitivitaet}
%  Eine Relation $R \subseteq \setU\times\setU$ heisst {\em transitiv}, wenn $R$ unter der monotonen
%  Funktion
%  \[\begin{array}{rl}
%    \name{TR}: & \mathcal{P}(\setU\times\setU) \to \mathcal{P}(\setU\times\setU) \\
%               & X \mapsto \{(x,y)\ |\ \exists z\in\setU:(x,z),(z,y)\in X\}
%  \end{array}\]
%  abgeschlossen ist, also wenn $\name{TR}(R) \subseteq R$.
%\end{definition}
%
%\begin{definition}[Symmetrie] \label{definition:math:Symmetrie}
%  Eine Relation $R \subseteq \setU\times\setU$ heisst {\em symmetrisch}, wenn $R$ unter der monotonen
%  Funktion
%  \[\begin{array}{rl}
%    \name{SYMM}: & \mathcal{P}(\setU\times\setU) \to \mathcal{P}(\setU\times\setU) \\
%                 & X \mapsto \{(x,y)\ |\ (y,x)\in X\}
%  \end{array}\]
%  abgeschlossen ist, also wenn $\name{SYMM}(R) \subseteq R$.
%\end{definition}
%
%{\bf TODO:} \"Uberleitung
%
%\begin{lemma} \label{lemma:math:Reflexivitaet}
%  Sei $F: \mathcal{P}(\setU\times\setU) \to \mathcal{P}(\setU\times\setU)$ eine monotone Funktion.
%  $\nu F$ ist reflexiv, wenn $\name{Refl}_{\setU}$ $F$-konsistent ist.
%\end{lemma}
%
%\begin{beweis}
%  Klar, da $\nu F$ nach Satz~\ref{satz:math:Knaster_Tarski} die Vereinigung aller $F$-konsistenten Relationen ist.
%\end{beweis}
%
%\begin{lemma} \label{lemma:math:Transitivitaet}
%  Sei $F: \mathcal{P}(\setU\times\setU) \to \mathcal{P}(\setU\times\setU)$ eine monotone Funktion.
%  $\nu F$ ist transitiv, wenn $\name{TR}(F(R)) \subseteq F(\name{TR}(R))$ f\"ur alle $R \subseteq \setU\times\setU$.
%\end{lemma}
%
%\begin{beweis}
%  Es gilt $\name{TR}(\nu F) \subseteq \name{TR}(F(\nu F))$, da $\name{TR}$ eine monotone Funktion und $\nu F$ ein
%  Fixpunkt von $F$ ist. Nach Voraussetzung folgt daraus $\name{TR}(\nu F) \subseteq F(\name{TR}(\nu F))$, d.h.
%  $\name{TR}(\nu F)$ ist $F$-konsistent. Gem\"a"s dem Prinzip der Koinduktion gilt dann $\name{TR}(\nu F) \subseteq \nu F$,
%  und somit ist gezeigt dass $\nu F$ transitiv ist (vgl. Definition~\ref{definition:math:Transitivitaet}).
%\end{beweis}
%
%\begin{lemma} \label{lemma:math:Symmetrie}
%  Sei $F: \mathcal{P}(\setU\times\setU) \to \mathcal{P}(\setU\times\setU)$ eine monotone Funktion.
%  $\nu F$ ist symmetrisch, wenn $\name{SYMM}(F(R)) \subseteq F(\name{SYMM}(R))$ f\"ur alle
%  $R \subseteq \setU\times\setU$.
%\end{lemma}
%
%\begin{beweis}
%  Verl\"auft analog zum Beweis von Lemma~\ref{lemma:math:Transitivitaet}.
%\end{beweis}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Die funktionale Programmiersprache Lf %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Die funktionale Programmiersprache \Lf}

Einf\"uhrend soll kurz die funktionale Programmiersprache \Lf\ vorgestellt werden, die als
Grundlage f\"ur die weiteren Betrachtungen in diesem Dokument dient. Hierbei handelt es
sich um einen ungetypten $\lambda$-Kalk\"ul mit Konstanten, der im wesentlichen
mit dem in der Vorlesung "`Theorie der Programmierung I"' (\cite{Sieber04}, \cite{Sieber06})
vorgestellten "ubereinstimmt.

{\bf TODO:} Etwas zu {\em structual typing} erz\"ahlen, insb. der Unterschied zu Java, o.\"a.


%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Syntax der Sprache Lf %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Syntax der Sprache \Lf}

Die Programmiersprache \Lf\ orientiert sich, wie auch alle weiteren in diesem Dokument betrachteten Sprachen,
syntaktisch stark an der Programmiersprache O'Caml\footnote{\url{http://caml.inria.fr/ocaml/}}, da O'Caml
als Grundlage f\"ur den Inhalt der Vorlesung "`Theorie der Programmierung"' dient. Bis auf kleinere syntaktische
Unterschiede handelt es sich bei \Lf\ um die funktionalen Sprache Caml
Light\footnote{\url{http://caml.inria.fr/caml-light/}}, den Vorg\"anger von O'Caml, allerdings verzichten wir auf
einige Konzepte wie Pattern Matching und Exceptions, da diese f\"ur die Betrachtungen in diesem Dokument nicht
relevant sind. ({\bf TODO:} ggfs. sp\"ater auf Exceptions eingehen)
\begin{definition}
  Vorgegeben sei
  \begin{enumerate}
    \item eine unendliche Menge $\setVar$ von \Define{Variablen}{Variable} $x$,
    \item eine Menge $\setInt$ (von Darstellungen) ganzer Zahlen $n$ und
    \item die Menge $\setBool = \{\false,\true\}$ der boolschen Werte $b$.
  \end{enumerate}
\end{definition}
W\"ahrend reale Programmiersprachen die Menge $\setVar$ bestimmten Beschr\"ankungen
unterwerfen, die zumeist auf Einschr\"ankungen der konkreten Syntax zur\"uckzuf\"uhren
sind, wie zum Beispiel, dass $\setVar$ keine Schl\"usselw\"orter der Sprache enthalten
darf, fordern wir lediglich, dass $\setVar$ mindestens abz\"ahlbar unendlich ist.

Auch m\"usste in einer realen Programmiersprache spezifiziert werden, was genau unter
der Darstellung einer ganzen Zahl $n \in \setInt$ verstanden werden soll. F\"ur die
Betrachtungen in diesem Dokument sind diese Aspekte allerdings irrelevant, und wir
nehmen deshalb an, dass die beiden Mengen $\setInt$ und $\setZ$ rekursiv isomorph
sind und unterscheiden nicht weiter zwischen einer ganzen Zahl und ihrer Darstellung.

\begin{definition}[Abstrakte Syntax von \Lf]
  Die Menge $\setOp$ aller Operatoren $\op$ ist definiert durch die kontextfreie Grammatik
  \[\begin{array}{rrcccccccccl}
  \op \GRis + & \mid & - & \mid &  *  &      &     &      &   \GRtext{arithmetische Operatoren}
      \GRal < & \mid & > & \mid & \le & \mid & \ge & \mid & = \GRtext{Vergleichsoperatoren,}
  \end{array}\]
  die Menge $\setConst$ aller Konstanten $c$ durch
  \GRbeg
  c \GRis ()  \GRtext{\bunit-Element}
    \GRal b   \GRtext{boolscher Wert}
    \GRal n   \GRtext{Ganzzahl}
    \GRal \op \GRtext{Operator}
  \GRend
  und die Menge $\setExp$ aller \Define{Ausdr\"ucke}{Ausdruck} $e$ von \Lf\ durch
  \GRbeg
  e \GRis c                       \GRtext{Konstante}
    \GRal x                       \GRtext{Variable}
    \GRal \expApp{e_1}{e_2}       \GRtext{Applikation}
    \GRal \expAbstr{x}{e_1}       \GRtext{$\lambda$-Abstraktion}
    \GRal \expRec{x}{e_1}         \GRtext{rekursiver Ausdruck}
    \GRal \expLet{x}{e_1}{e_2}    \GRtext{\blet-Ausdruck}
    \GRal \expCond{e_0}{e_1}{e_2} \GRtext{bedingter Ausdruck.}
  \GRend
\end{definition}
Dem aufmerksamen Leser wird sicherlich nicht entgangen sein, dass keine Operatoren f\"ur
Ganzzahldivision und Divisionsrest existieren. Diese wurden bewusst weggelassen, da eine
Hinzunahme dieser Operatoren zur Kernsprache eine Laufzeitfehlerbehandlung notwendig
macht, welche unsere Betrachtungen der Sprache unn\"otig kompliziert machen w\"urden. Wir
werden Laufzeitfehlerbehandlung sp\"ater als Erweiterung der Kernsprache betrachten ({\bf TODO:} Nur, wenn
das Exception-Kapitel rein kommt).

Nichtsdestrotrotz ist die Programmiersprache \Lf\ hinreichend m\"achtig. Im weiteren Verlauf dieses
Kapitels werden die Funktionen $div$ und $mod$ vorgestellt, die als Grundlage f\"ur die Einf\"uhrung
der Operatoren f\"ur Ganzzahldivision und Divisionsrest als syntaktischer Zucker in die Sprache dienen
k\"onnten. ({\bf TODO:} Was'n das f\"ur'n komischer Satz?)


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Frei vorkommende Variablen und Substitution %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Frei vorkommende Variablen und Substitution}

{\bf TODO:} Blah blub

\begin{definition}[Frei vorkommende Variablen] \label{definition:Lf:Frei_vorkommende_Variablen} \
  Die Menge $\free{e}$ aller im Ausdruck $e \in \setExp$ \Define{frei vorkommenden Variablen}{Frei
  vorkommende Variablen} ist wie folgt induktiv definiert.
  \EQNbeg
    \free{c}                       & = & \emptyset \\
    \free{x}                       & = & \{x\} \\
    \free{\expApp{e_1}{e_2}}       & = & \free{e_1}\,\cup\,\free{e_2} \\
    \free{\expAbstr{x}{e}}         & = & \free{e} \setminus \{x\} \\
    \free{\expRec{x}{e}}           & = & \free{e} \setminus \{x\} \\
    \free{\expLet{x}{e_1}{e_2}}    & = & \free{e_1}\,\cup\,\left(\free{e_2} \setminus \{x\} \right) \\
    \free{\expCond{e_0}{e_1}{e_2}} & = & \free{e_0}\,\cup\,\free{e_1}\,\cup\,\free{e_2}
  \EQNend
\end{definition}

{\bf TODO:} Blub blah

\begin{definition}
  Ein Ausdruck $e~\in~\setExp$ heisst \Define{abgeschlossen}{Abgeschlossenheit}, wenn $\free{e}~=~\emptyset$.
\end{definition}

{\bf TODO:} Beispiel

Es ist leicht zu sehen, dass gem\"a"s dieser Definition, ein Ausdruck genau dann abgeschlossen ist,
wenn er keine freien Vorkommen von Variablen enth\"alt. Zum Beispiel sind im Ausdruck
\[
  \expApp{f}{(x + 1)}
\]
die beiden Vorkommen der Variablen $f$ und $x$ frei, der Ausdruck also nicht abgeschlossen.
Erweitert man hingegen den Ausdruck zu
\[
  \expLet{f}{\expAbstr{y}{y*y}}{\expLet{x}{2}{\expApp{f}{(x + 1)}}}
\]
so werden nun beide zuvor freien Vorkommen von Variablen durch $\blet$-Ausdr\"ucke gebunden und der
Gesamtausdruck ist abgeschlossen.


\begin{definition}[Substitution] \label{definition:Lf:Substitution}
  F\"ur $e,e'\in\setExp$ und $x\in\setVar$ ist der Ausdruck $e'\SUB{e}{x}$, der aus
  $e'$ durch \define{Substitution} von $e$ f\"ur $x$ entsteht, wie folgt induktiv \"uber
  die Gr\"osse von $e$ definiert.
  \EQNbeg
    c\SUB{e}{x} & = &
      c
    \\[1mm]

    x'\SUB{e}{x} & = &
      \CASEbeg
        e    & \text{falls } x = x' \\
        x' & \text{sonst}
      \CASEend
    \\[4mm]

    (\expApp{e_1}{e_2})\SUB{e}{x} & = &
      \expApp{e_1\SUB{e}{x}}{e_2\SUB{e}{x}}
    \\[1mm]

    (\expAbstr{x'}{e'})\SUB{e}{x} & = &
      \expAbstr{x'}{e'\SUB{e}{x}} \\
      && \text{falls } x' \not\in \{x\} \cup \free{e}
    \\[1mm]

    (\expRec{x'}{e'})\SUB{e}{x} & = &
      \expRec{x'}{e'\SUB{e}{x}} \\
      && \text{falls } x' \not\in \{x\} \cup \free{e}
    \\[1mm]

    (\expLet{x'}{e_1}{e_2})\SUB{e}{x} & = &
      \expLet{x'}{e_1\SUB{e}{x}}{e_2\SUB{e}{x}} \\
      && \text{falls } x' \not\in \{x\} \cup \free{e}
    \\[1mm]

    (\expCond{e_0}{e_1}{e_2})\SUB{e}{x} & = &
      \expCond{e_0\SUB{e}{x}}{e_1\SUB{e}{x}}{e_2\SUB{e}{x}}
  \EQNend
\end{definition}

Gem\"a"s obiger Definition ist allerdings die Substitution in dieser Form eine partielle Funktion. Zum
Beispiel ist
\[
  (\expAbstr{x}{\expApp{x}{y}})\SUB{x}{y}
\]
nicht definiert, da $x \in \free{x}$. Wir treffen deshalb die folgende Vereinbarung (vgl. \cite[S. 71]{Pierce02}).
\begin{konvention} \label{konvention:Lf:Ausdruecke_und_alpha_Konversion}
  Ausdr\"ucke, die sich lediglich in den Namen von gebundenen Variablen unterscheiden, sind in
  jeder Beziehung austauschbar.
\end{konvention}
Wenn wir nun im Beispiel die gebundene Variable $x$ umbenennen, zum Beispiel in $x'$, so erhalten wir
\[
  (\expAbstr{x'}{\expApp{x'}{y}})\SUB{x}{y}
\]
und die Substitution ist definiert, da $x' \not\in \{y\} \cup \free{x}$. Dieses Austauschen der
Namen gebundener Variablen wird in der Literatur als \define{gebundene Umbenennung} oder auch
\define{$\alpha$-Konversion} ({\bf TODO:} Quelle Church) bezeichnet.

Verm\"oge dieser Konvention ist die Substitution nun eine totale Funktion. Denn falls eine
Bedingung f\"ur die Substitution nicht erf\"ullt ist, k\"onnen im Ausdruck gebundene Variablen
entsprechend umbenannt werden, so dass die Bedingung erf\"ullt wird. Insbesondere sei daran
erinnert, dass $\setVar$ mindestens abz\"ahlbar unendlich ist, und somit stets "`ein
neuer Name gefunden werden kann"'.

Gem\"a"s dieser Betrachtungen k\"onnten wir die Anwendung der Substitution auf $\lambda$-Ausdr\"ucke
auch wie folgt definieren.
\EQNbeg
  (\expAbstr{x'}{e'})\SUB{e}{x} & = &
    \expAbstr{x''}{e'\SUB{x''}{x'}\SUB{e}{x}} \\
    && \text{mit } x'' \not\in \{x\} \cup \free{e} \cup \free{\expAbstr{x'}{e'}}
\EQNend
Und entsprechend k\"onnten auch die F\"alle f\"ur $\brec$- und $\blet$-Ausdr\"ucke angepasst werden.
Weiter k\"onnen wir zeigen, dass wir f\"ur jeden solchen Ausdruck in effektiver Weise ein $x''$
angeben k\"onnen, welches die Bedingung erf\"ullt. Zum Beispiel verwendet das an der Universit\"at
Siegen entwickelte Lernwerkzeug TPML\footnote{\url{http://www.informatik.uni-siegen.de/theo/tpml/}}
den folgenden einfachen Algorithmus.
\begin{lstlisting}[basicstyle=\small,language=Java]
  public String generateVar (String var, Set forbidden) {
    while (forbidden.contains (var))
      var = var + "'";
    return var;
  }
\end{lstlisting}
Im Falle der $\lambda$-Abstraktion wird $\mathtt{generateVar}$ dann mit $x'$ und
$\{x\} \cup \free{e} \cup \free{\expAbstr{x'}{e'}}$ aufgerufen und liefert einen
"`neuen"' Namen. Dazu werden lediglich solange Hochstriche an den Namen angeh\"angt, bis
ein Name gefunden wird, der nicht in der Menge der verbotenen Namen auftaucht. Da die Menge
der verbotenen Namen offensichtlich endlich ist, findet der Algorithmus stets nach
endlich vielen Schritten einen Namen, der nicht in dieser Liste auftaucht.

Damit kann f\"ur die Substitution ein Algorithmus formuliert werden kann, der die
notwendigen gebundenen Umbenennung bei Bedarf durchf\"uhrt. Es bleibt also festzuhalten,
dass die Substitution eine totale, berechenbare Funktion ist.

Der Aspekt der Berechenbarkeit der Substitution spielt allerdings f\"ur die theoretischen
Betrachtungen eine untergeordnete Rolle. Entscheidend ist, dass wir gem\"a"s der
getroffenen Vereinbarung, die Substitution als eine totale Funktion betrachten k\"onnen.


%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Syntaktischer Zucker %%
%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Syntaktischer Zucker}

\[\begin{array}{ccll}
e_1\,\op\,e_2 & \text{f\"ur} & \expApp{\expApp{\op}{e_1}}{e_2} & \quad \quad \text{Infixnotation} \\
-e            & \text{f\"ur} & 0\,-\,e                         & \quad \quad \text{un\"ares Minus}
\end{array}\]

{\bf TODO:} Die bereits angesprochenen $div$ und $mod$, Division durch $0$ ist nicht
definiert.

\[\begin{array}{rcl}
  div & = & \brec\,div.\lambda x.\lambda y. \\
      &   & \quad \quad \bif\,x<y\,\bthen\,0 \\
      &   & \quad \quad \belse\,\left(div\,\left(x-y\right)\,y\right)+1 \\
  \\
  mod & = & \lambda x.\lambda y.x-y*\left(div\,x\,y\right)
\end{array}\]

Der Leser mag sich selbst davon \"uberzeugen, dass diese Implementationen gem\"a"s der
im n\"achsten Abschnitt vorgestellten Semantik korrekt sind.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Operationelle Semantik der Sprache Lf %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Operationelle Semantik der Sprache \Lf}

In der \Define{operationellen Semantik}{Operationelle Semantik} einer Programmiersprache
beschreibt man die Auswertung von Ausdr\"ucken als ein Verfahren zur {\em Umformung} oder
{\em Vereinfachung} der Ausdr\"ucke. Im Gegensatz dazu versucht man in der denotationellen
Semantik die Konstrukte der Programmiersprache direkt durch mathematische Funktionen zu
beschreiben. Denotationelle Semantiken bieten einige Vorteile gegen\"uber der Beschreibung
durch operationelle Semantik, sie sind daf\"ur allerdings schwer oder garnicht erweiterbar,
so dass f\"ur alle in diesem Dokument beschriebenen Sprachen jeweils neue Semantiken
angeben m\"ussten. Aus diesem Grund verwenden wir ausschliesslich operationelle Semantik
zur Beschreibung der Programmiersprache.

F\"ur die Beschreibung der Umformung von Ausdr\"ucken in pr\"aziser mathematischer Form bieten
sich zwei M\"oglichkeiten an, n\"amlich
\begin{enumerate}
  \item eine {\em iterative} Definition, bei der man explizit die einzelnen Umformungsschritte
        angibt, die aneinandergereiht werden d\"urfen,
  \item oder eine {\em rekursive} Definition, bei der man das Ergebnis einer Umformung auf
        die Ergebnisse von {\em Teilumformungen} zur\"uckf\"uhrt.
\end{enumerate}
Den iterativen Ansatz bezeichnet man als {\em small step Semantik}\index{small step!Semantik},
den rekursiven Ansatz als {\em big step Semantik}\index{big step!Semantik}. Die small step
Semantik eignet sich besonders gut f\"ur theoretische Betrachtungen, w\"ahrend die big step
Semantik besser geeignet ist als Grundlage f\"ur die Implementation eines Interpreters. Wir
werden uns deshalb zun\"achst ausschliesslich mit der small step Semantik f\"ur die
Programmiersprachen \Lf\ und \Lo\ besch\"aftigen, und sp\"ater eine \"aquivalente big step
Semantik f\"ur die Programmiersprache \Lo\ entwickeln.

Bevor wir uns nun der Definition der small step Semantik zuwenden, ben\"otigen wir
noch einige allgemeine Definition. Zun\"achst m\"ussen wir festlegen, wie die Operatoren
der Sprache zu interpretieren sind.
\begin{definition}
  F\"ur jeden Operator $\op \in \setOp$ sei eine Funktion $\op^I$ vorgegeben mit
  \[\begin{array}{ll}
    \op^I:\setInt\times\setInt\to\setInt  & \text{ falls } \op \in \{+,-,*\} \\
    \op^I:\setInt\times\setInt\to\setBool & \text{ sonst.}
  \end{array}\]
  Die Funktion $\op^I$ heisst {\em Interpretation} des Operators $\op$.
\end{definition}
Auf eine exakte Definition der Interpretationen der verschiedenen Operatoren wird
hier verzichtet. Stattdessen nehmen wir an, dass diese Funktionen entsprechend ihrer
intuitiven Bedeutung definiert sind. Zum Beispiel entspricht also die Interpretation
des Stern-Operators der Multiplikation
\[
  *^I: \setInt \times \setInt \to \setInt,\ (x,y) \mapsto x \cdot y
\]
und die Interpretation des $<$-Operators der charakteristischen Funktion der
$<$-Relation auf den ganzen Zahlen
\[
  <^I: \setInt \times \setInt \to \setBool,\ (x,y) \mapsto \CASEbeg
                                                             \true  & \text{falls } x < y \\
                                                             \false & \text{sonst}
                                                           \CASEend
\]
wobei wir nach Vereinbarung zwischen $\setZ$ und $\setInt$ nicht unterscheiden.
\begin{definition}
  \label{definition:Lf:Werte}
  Die Menge $\setVal \subseteq \setExp$ aller Werte $v$ ist durch die kontextfreie
  Grammatik
  \GRbeg
  v \GRis c                 \GRtext{Konstante}
    \GRal x                 \GRtext{Variable}
    \GRal \expApp{\op}{v_1} \GRtext{partielle Applikation}
    \GRal \expAbstr{x}{e_1} \GRtext{$\lambda$-Abstraktion}
  \GRend
  definiert.
\end{definition}
Im Terminus funktionaler Programmiersprachen ist ein Wert ein vollst\"andig ausgewerteter
Ausdruck, der nicht weiter vereinfacht werden kann. Man beachte, dass insbesondere $\lambda$-Abstraktionen,
also Funktionen, bereits Werte sind. Dies l\"asst sich intuitiv einfach dadurch erkl\"aren, dass
eine Funktion erst nach Anwendung auf ein Argument weiter ausgewertet werden kann. Entsprechendes
gilt f\"ur Operatoren mit einem Operanden, da hier die Auswertung erst erfolgen kann, wenn beide
Operanden vorhanden sind.

In diesem Kontext ist es auch \"ublich partielle Applikationen als Funktionen zu lesen.
Beispielsweise entspricht der Ausdruck $\expApp{+}{1}$ der Nachfolgerfunktion auf den
ganzen Zahlen, also der Funktion, die $1$ auf ihr Argument addiert.


%%%%%%%%%%%%%%%%%%%%%%%%%
%% Small step Semantik %%
%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Small step Semantik}

Nach diesen Vorbereitungen k\"onnen wir nun die {\em small step Regeln}\index{small step!Regeln} f\"ur die
Programmiersprache \Lf\ formulieren. Zun\"achst definieren wir dazu, was wir unter einem small step
verstehen.
\begin{definition}
  Ein \define{small step} ist eine Formel der Gestalt $e~\to_e~e'$ mit $e,e'~\in~\setExp$.
\end{definition}
Um small steps herleiten zu k\"onnen ben\"otigen wir einen Satz von Regeln, der durch die folgende
Definition bestimmt wird.
\begin{definition}[G"ultige small steps f"ur \Lf] \label{definition:Lf:Gueltige_small_steps}
  Ein small $e~\to_e~e'$ mit $e,e'~\in~\setExp$ heisst g"ultig f"ur \Lf, wenn er sich mit
  den folgenden Regeln herleiten l"asst. \\[5mm]
  \begin{tabular}{ll}
    \RN{Op}         & $\expApp{\expApp{\op}{n_1}}{n_2} \to_e \op^I(n_1,n_2)$ \\[3mm]
    \RN{Beta-V}     & $\expApp{(\expAbstr{x}{e})}{v} \to_e e\SUB{v}{x}$ \\[3mm]
    \RN{App-Left}   & $\RULE{e_1 \to_e e_1'}
                            {\expApp{e_1}{e_2} \to_e \expApp{e_1'}{e_2}}$ \\[3mm]
    \RN{App-Right}  & $\RULE{e_2 \to_e e_2'}
                            {\expApp{v_1}{e_2} \to_e \expApp{v_1}{e_2'}}$ \\[5mm]
    \RN{Unfold}     & $\expRec{x}{e} \to_e e\SUB{\expRec{x}{e}}{x}$ \\[3mm]
    \RN{Let-Eval}   & $\RULE{e_1 \to_e e_1'}
                            {\expLet{x}{e_1}{e_2} \to_e \expLet{x}{e_1'}{e_2}}$ \\[5mm]
    \RN{Let-Exec}   & $\expLet{x}{v_1}{e_2} \to_e e_2\SUB{v_1}{x}$ \\[3mm]
    \RN{Cond-Eval}  & $\RULE{e_0 \to_e e_0'}
                            {\expCond{e_0}{e_1}{e_2} \to_e \expCond{e_0'}{e_1}{e_2}}$ \\[5mm]
    \RN{Cond-True}  & $\expCond{\true}{e_1}{e_2} \to_e e_1$ \\[3mm]
    \RN{Cond-False} & $\expCond{\false}{e_1}{e_2} \to_e e_2$ \\[3mm]
  \end{tabular}
\end{definition}
Das Regelwerk entspricht den small step Regeln der Programmiersprache \Ltwo\ aus der Vorlesung
"`Theorie der Programmierung"' (\cite{Sieber06}). Nachfolgend sollen die einzelnen Regeln kurz
erl\"autert werden.
\begin{itemize}
  \item \RN{Op} besagt, dass die Anwendung eines Operators auf zwei ganze Zahlen das
        intuitive Ergebnis liefert, zum Beispiel $\expApp{\expApp{*}{21}}{2} \to 42$.
  \item Die Regel \RN{Beta-V}, die als $\beta$-{\em value}-Regel bezeichnet wird, beschreibt
        die Parameter\"ubergabe: Die Anwendung einer Funktion $\expAbstr{x}{e}$ auf einen
        Wert $v$ bewirkt, dass jedes Vorkommen des formalen Parameters $x$ im Rumpf $e$
        durch den aktuellen Parameter $v$ ersetzt wird. Zu beachten ist, dass \RN{Beta-V}
        nur anwendbar ist, wenn der aktuelle Parameter ein Wert, also schon vollst\"andig
        ausgewertet ist\footnote{Man bezeichnet diese Art der Parameter\"ubergabe als
        {\em call-by-value}. Die unausgewertete Parameter\"ubergabe wird als
        {\em call-by-name} bezeichnet.}.
  \item Die Regel \RN{App-Left} erlaubt es den linken Teil einer Applikation weiter
        auszuwerten, zum Beispiel solange, bis eine $\lambda$-Abstraktion erreicht ist.
  \item Die Regel \RN{App-Right} erlaubt es das Argument einer Applikation
        auszuwerten\footnote{Diese Regel wird unter anderem ben\"otigt, um im Zusammenspiel
        mit \RN{Beta-V} das {\em call-by-value}-Prinzip zu realisieren.}.
  \item \RN{Unfold} faltet einen rekursiven Ausdruck auf, indem der vollst\"andige Ausdruck
        f\"ur jedes Vorkommen des formalen Parameters $x$ im Rumpf $e$ eingesetzt wird.
  \item \RN{Let-Eval} wertet den Teilausdruck $e_1$ eines $\blet$-Ausdrucks aus.
  \item Die Regel \RN{Let-Exec} greift, sobald der erste Teilsausdruck ausgewertet ist, und
        setzt dessen Wert $v_1$ f\"ur den formalen Parameter $x$ in $e_2$ ein.
  \item \RN{Cond-Eval} erlaubt es, die Bedingung $e_0$ eines bedingten Ausdrucks auszuwerten.
  \item Die Regeln \RN{Cond-True} und \RN{Cond-False} greifen, sobald die Bedingung eines
        bedingten Ausdrucks zu einer boolschen Konstanten ausgewertet ist.
\end{itemize}


% vi:set ts=2 sw=2 et ai syntax=tex:
